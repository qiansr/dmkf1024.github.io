---
title: 【门外汉深度学习-4】深度网络的选择
date: 2017-04-02 12:03:54
tags:
	- 机器学习
	- 神经网络
	- 深度网络
	- 深度学习
	- Youtube
categories: 机器学习
---

# 前言
本文源自YouTube网站《[Deep Learning SIMPLIFIED](https://www.youtube.com/watch?v=b99UVkWzYTQ&index=1&list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu)》系列视频，文章内容为视频的字幕，供深度学习初学者参考学习。

# 主体内容

![](http://upload-images.jianshu.io/upload_images/291600-619b127bca41e211.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

Now if you're like me, starting a Deep Learning project sounds really exciting. But when it comes to picking the right kind of net to use, well, things can get a little confusing. You first need to decide if you're trying to build a classifier or if you're trying to find patterns in your data. Beyond that, I'll try to help by giving you some general guidelines.

![](http://upload-images.jianshu.io/upload_images/291600-76939354a6feb347.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

Before we get started, I want to give you a bit of a heads up. I'm going to be using some terminology that may sound a little scary right now, but don't worry. I'll cover all these terms in detail in the upcoming videos. If you're interested in unsupervised learning - that is, you want to extract patterns from a set of unlabelled data - then your best bet is to use either a **Restricted Boltzmann Machine**（受限波兹曼机）, or an **autoencoder**（自编码器）. What type of projects would you need to use a Deep Net for? Please comment and let me know your thoughts.

![](http://upload-images.jianshu.io/upload_images/291600-7884bb2e63a021b2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

If you have labeled data for supervised learning and you want to build a classifier, you have several different options depending on your application.

![](http://upload-images.jianshu.io/upload_images/291600-823c5c38d048857c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

For text processing tasks like sentiment analysis, parsing, and named entity recognition - use a **Recurrent Net** or a **Recursive Neural Tensor Network**（递归神经张量网络）,  which we'll refer to as an ***RNTN***. For any language model that operates on the character level, use a **Recurrent Net**.

![](http://upload-images.jianshu.io/upload_images/291600-b1a4ef267c3ec0cf.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

For image recognition, use a **Deep Belief Network**（深度信念网络） or a **Convolutional Net**（卷积网络）.

![](http://upload-images.jianshu.io/upload_images/291600-497cefdaca33e995.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

For object recognition, use a **Convolutional Net** or an ***RNTN***.

![](http://upload-images.jianshu.io/upload_images/291600-fe7fb3ba4da4746e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

Finally, for speech recognition, use a **Recurrent Net**.

![](http://upload-images.jianshu.io/upload_images/291600-7864a9362e15672b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

Ingeneral, **Deep Belief Networks** and **Multilayer Perceptrons**（多层感知机） with rectified linear units - also known as ***RELU*** - are both good choices for classification. For time series analysis, it's best to use a **Recurrent Net**. 

![](http://upload-images.jianshu.io/upload_images/291600-edc84d593ae3c095.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

Deep Nets are the current state of the art in pattern recognition, but it's worth noting that neural nets have been around for decades.

![](http://upload-images.jianshu.io/upload_images/291600-da7f39818a2bacf7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

 So you might be wondering: why did it take almost 50 years for Deep Nets to come on to the scene? Well, as it turns out, Deep Nets are very hard to train, which we will see in the next video.

![](http://upload-images.jianshu.io/upload_images/291600-f7ab81d3c318996b.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/350)

# 相关链接
[视频链接](https://www.youtube.com/watch?v=JjZDoojyzXQ&index=4&list=PLjJh1vlSEYgvGod9wWiydumYl8hOXixNu)
[本系列文章目录](http://www.jianshu.com/p/4f7e4f27dad9)

# 拓展阅读
* [Deep Belief Network简介](http://www.cnblogs.com/kemaswill/p/3266026.html)
* [CNN&RELU&POOL 感觉没有比这篇文章讲的更详细了](http://blog.sina.com.cn/s/blog_69e2aa270102ygvh.html)